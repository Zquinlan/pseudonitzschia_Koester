runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories)%>%
select(date, cases, deaths, country)%>%
mutate(date = as.Date(date, "%d/%m/%y"),
location_type = "country",
country = gsub("_", " ", country),
country = case_when(country == "CuraÃ§ao" ~ "Curacao",
TRUE ~ as.character(country)))%>%
group_by(country)%>%
arrange(date)%>%
mutate('Cummulative Cases' = cases + lag(cases, default = first(date)))%>%
filter(date != "2020-12-31")%>%
ungroup()
View(countries_raw)
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories)%>%
select(date, cases, deaths, country)%>%
mutate(date = as.Date(date, "%d/%m/%y"),
location_type = "country",
country = gsub("_", " ", country),
country = case_when(country == "CuraÃ§ao" ~ "Curacao",
TRUE ~ as.character(country)))%>%
group_by(country)%>%
arrange(date)%>%
mutate('Cummulative Cases' = cumsum(cases))%>%
filter(date != "2020-12-31")%>%
ungroup()
View(countries_raw)
runApp('Documents/GitHub/covid')
head(countries_raw)
runApp('Documents/GitHub/covid')
View(countries_raw)
runApp('Documents/GitHub/covid')
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories,
`Cases per day` = cases)%>%
select(date, `Cases per day`, deaths, country)%>%
mutate(date = as.Date(date, "%d/%m/%y"),
location_type = "country",
country = gsub("_", " ", country),
country = case_when(country == "CuraÃ§ao" ~ "Curacao",
TRUE ~ as.character(country)))%>%
group_by(country)%>%
arrange(date)%>%
mutate('Cummulative Cases' = cumsum(`Cases per day`))%>%
filter(date != "2020-12-31")%>%
ungroup()
runApp('Documents/GitHub/covid')
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories,
`Cases per day` = cases)%>%
select(date, `Cases per day`, deaths, country)%>%
mutate(date = as.Date(date, "%d/%m/%y"),
location_type = "country",
country = gsub("_", " ", country),
country = case_when(country == "CuraÃ§ao" ~ "Curacao",
TRUE ~ as.character(country)))%>%
group_by(country)%>%
arrange(date)%>%
mutate(`Cases per day` = as.numeric(`Cases per day`),
'Cummulative Cases' = cumsum(`Cases per day`))%>%
filter(date != "2020-12-31")%>%
ungroup()
head(countries_raw)
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
?navlistPanel
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
head(countries_raw)
runApp('Documents/GitHub/covid')
#read and clean the state data
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date),
location_type = "state")%>%
group_by(state)%>%
arrange(date)%>%
mutate(new_cases = cases - lag(cases, default = first(date)),
new_cases = case_when(new_cases < 0 ~ 0,
TRUE ~ as.numeric(new_cases)))%>%
ungroup()
# Downlaod state data
state_url <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"
#read and clean the state data
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date),
location_type = "state")%>%
group_by(state)%>%
arrange(date)%>%
mutate(new_cases = cases - lag(cases, default = first(date)),
new_cases = case_when(new_cases < 0 ~ 0,
TRUE ~ as.numeric(new_cases)))%>%
ungroup()
head(state_raw)
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
countries_filtered%>%
ggplot(aes(date, plot, color = country)) +
geom_line() +
geom_point() +
scale_x_date(date_breaks = "4 days", limits = c(Sys.Date() - input$previous_days_country, NA), date_labels = "%b %d") +
xlab(paste("Date (past", input$previous_days_country, "days)")) +
ylab(input$data_type_country) +
scale_y_log10(limits = c(1, max(countries_filtered$plot + 5000)),
breaks = trans_breaks("log10", function(x) 10^x)) +
# scale_color_manual(values = wes_palette("Darjeeling1", 5, type = c('discrete'))) +
ggtitle("CoVID-19 cases by country") +
theme(
axis.text.x = element_text(angle = 60, size = 15, hjust = 1),
axis.text.y = element_text(size = 15),
axis.title = element_text(size = 17),
panel.background = element_rect(fill = "transparent"),
plot.background = element_rect(fill = "transparent", color = NA),
panel.grid.major.y = element_line(size = 0.2, linetype = 'solid',colour = "gray"),
panel.grid.minor.y = element_line(size = 0.2, linetype = 'solid',colour = "gray"),
panel.grid.major.x = element_line(size = 0.2, linetype = 'solid',colour = "gray"),
legend.background = element_rect(fill = "transparent"),
legend.box.background = element_rect(fill = "transparent"),
legend.text = element_text(size = 15),
legend.title = element_text(size = 17),
legend.position = "right",
plot.title = element_text(hjust = 0.5, size = 25))
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
rsconnect::deployApp('~/Documents/GitHub/covid/')
#plotting
## Download country data
GET("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv", authenticate(":", ":", type="ntlm"), write_disk(tf <- tempfile(fileext = ".csv")))
library(tidyverse)
library(readxl)
library(httr)
library(wesanderson)
library(scales)
#plotting
## Download country data
GET("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv", authenticate(":", ":", type="ntlm"), write_disk(tf <- tempfile(fileext = ".csv")))
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories,
`Cases per day` = `cases`,
Deaths = deaths)%>%
group_by(country)%>%
arrange(date)%>%
mutate(`Total Confirmed Cases` = cumsum(`Cases per day`))%>%
ungroup()%>%
select(date, country, input$data_type_country)%>%
rename(plot = 3)%>%
mutate(date = as.Date(date, "%d/%m/%y"),
country = gsub("_", " ", country),
country = case_when(country == "CuraÃ§ao" ~ "Curacao",
TRUE ~ as.character(country)))%>%
filter(date != "2020-12-31")
View(countries_raw)
## read in dfs
countries_raw <-read_csv(tf)%>%
rename(date = dateRep,
country = countriesAndTerritories,
`Cases per day` = `cases`,
Deaths = deaths)%>%
group_by(country)%>%
arrange(date)%>%
mutate(`Total Confirmed Cases` = cumsum(`Cases per day`))%>%
ungroup()
View(countries_raw)
?population
?radioButtons
?radioButtons
shiny::runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
# Downlaod state data
state_url <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"
#read and clean the state data
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()
head(state_raw)
runApp('Documents/GitHub/covid')
?print
runApp('Documents/GitHub/covid')
test <- read_csv("~/Downloads/cc-est2018-alldata.csv"P))
test <- read_csv("~/Downloads/cc-est2018-alldata.csv")
head(test)
View(test)
census <- test%>% select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
filter(YEAR == "11", AGEGRP = 0)%>%
rename(state = STNAME,)
ensus <- test%>% select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
+ filter(YEAR == "11", AGEGRP = 0)%>%
+ rename(state = STNAME, county = CTYNAME, population = TOT_POP)%>%
select(state, county, population)
census <- test%>% select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>% filter(YEAR == "11", AGEGRP = 0)%>% rename(state = STNAME, county = CTYNAME, population = TOT_POP)%>% select(state, county, population)
census <- test%>%
select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
filter(YEAR == "11", AGEGRP = 0)%>%
rename(state = STNAME,
county = CTYNAME,
population = TOT_POP)%>%
select(state, county, population)
census <- test%>%
select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
filter(YEAR == "11", AGEGRP == 0)%>%
rename(state = STNAME,
county = CTYNAME,
population = TOT_POP)%>%
select(state, county, population)
census <- test%>%
select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
filter(YEAR == "11", AGEGRP == "0")%>%
rename(state = STNAME,
county = CTYNAME,
population = TOT_POP)%>%
select(state, county, population)
View(census)
census <- test%>%
select(STNAME, CTYNAME, YEAR, AGEGRP, TOT_POP)%>%
filter(YEAR == "11", AGEGRP == "0")%>%
rename(state = STNAME,
county = CTYNAME,
population = TOT_POP)%>%
select(state, county, population)%>%
mutate(county = gsub(" County", "", county))
write_csv(census, "~/Documents/GitHub/covid/us_census_data.csv")
census_url <- "https://raw.githubusercontent.com/Zquinlan/ShinyApp_CoVID19/master/us_census_data.csv"
#read and clean the state data
state_census <- read_csv(url(census_url))%>%
group_by(state)%>%
summarize_if(is.numeric, sum)
View(state_census)
runApp('Documents/GitHub/covid')
# Downlaod state data
state_url <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"
census_url <- "https://raw.githubusercontent.com/Zquinlan/ShinyApp_CoVID19/master/us_census_data.csv"
#read and clean the state data
county_census <- read_csv(url(census_url))
state_census <- county_census%>%
group_by(state)%>%
summarize_if(is.numeric, sum)
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()%>%
left_join(state_census, by = "state")%>%
select(date, state,cases, population)%>%
rename(plot = 3)%>%
plot = case_when(input$pop_divider_state == "Not relativized" ~ plot,
input$pop_divider_state == "Percent of Population" ~ plot/population*100,
input$pop_divider_state == "Cases per 100,000 people" ~ plot/population*100000)
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()%>%
left_join(state_census, by = "state")
View(state_raw)
runApp('Documents/GitHub/covid')
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()%>%
left_join(state_census, by = "state")
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()%>%
left_join(state_census, by = "state")
#read and clean the state data
county_census <- read_csv(url(census_url))%>%
mutate(population = as.numeric(population))
state_census <- county_census%>%
group_by(state)%>%
summarize_if(is.numeric, sum)
state_raw <- read_csv(url(state_url))%>%
select(-fips)%>%
mutate(date = as.Date(date))%>%
group_by(state)%>%
arrange(date)%>%
mutate(`Cases per day` = cases - lag(cases, default = first(date)),
`Cases per day` = case_when(`Cases per day` < 0 ~ 0,
TRUE ~ as.numeric(`Cases per day`)))%>%
rename(`Total Confirmed Cases` = cases,
Deaths = deaths)%>%
ungroup()%>%
left_join(state_census, by = "state")
View(state_raw)
test <- state_raw%>% mutate(test = `total Confirmed Cases`/population)
test <- state_raw%>% mutate(test = `Total Confirmed Cases`/population)
View(test)
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
rsconnect::deployApp('~/Documents/GitHub/covid/')
runApp('Documents/GitHub/covid')
runApp('Documents/GitHub/covid')
rsconnect::deployApp('~/Documents/GitHub/covid/')
rsconnect::deployApp('~/Documents/GitHub/covid/')
)
source('~/.active-rstudio-document', echo=TRUE)
analog <- read_csv('~/Downloads/RR3_Analog_InChI_ForClassyfire.csv')
library <- read_csv('~/Downloads/RR3_Library_InChI_ForClassyfire.csv')
View(library)
read_csv?
?read_csv
analog <- read_csv('~/Downloads/RR3_Analog_InChI_ForClassyfire.csv', col_names = FALSE)
library <- read_csv('~/Downloads/RR3_Library_InChI_ForClassyfire.csv', col_names = FALSE)%>%
mutate(inchikey = cs_inchi_inchikey(X2))
library <- read_csv('~/Downloads/RR3_Library_InChI_ForClassyfire.csv', col_names = FALSE)%>%
group_by(X1)%>%
mutate(inchikey = cs_inchi_inchikey(X2))
source('~/.active-rstudio-document', echo=TRUE)
write_csv(analog%>%
filter(~is.na(inchikey)), "rr3_analog_inchikey.csv")
write_csv(analog%>%
filter(!is.na(inchikey)), "rr3_analog_inchikey.csv")
write_csv(library%>%
filter(!is.na(inchikey)), "rr3_library_inchikey.csv")
write_csv(analog%>%
filter(!is.na(inchikey)), "~/Downloads/rr3_analog_inchikey.csv")
write_csv(library%>%
filter(!is.na(inchikey)), "~/Downloads/rr3_library_inchikey.csv")
analog_key <- read_csv('~/Downloads/analog.csv')
library_key <- read_csv('~/Downloads/library.csv')
view(library_key)
analog_key <- read_csv('~/Downloads/analog.csv')%>%
rename(inchikey =  1)
library_full <- library%>%
left_join(library_key, by = "inchikey")
library_key <- read_csv('~/Downloads/library.csv')%>%
rename(inchikey =  1)
library_full <- library%>%
left_join(library_key, by = "inchikey")
analog_full <- analog%>%
left_join(analog_key, by = "inchikey")
write_csv(analog_full, "~/Downloads/rr3_analog_classyfire.csv")
write_csv(library_full, "~/Downloads/rr3_library_classyfire.csv")
setwd("~/Documents/GitHub/pseudonitzschia_Koester/Data/")
# LOADING -- Libraries ----------------------------------------------------
## Load in all of the data frames and libraries
#Data manipulations
library(tidyverse)
library(data.table)
library(DescTools)
library(readxl)
library(CHNOSZ)
library(randomForest)
# PCoA and visualizations
library(vegan)
library(ape)
library(wesanderson)
# library(RColorBrewer)
# LOADING -- Functions ----------------------------------------------------
flag_background <- function(data,
min_val = 0.5,
blank_columns = match(names(select(data, contains("blank", ignore.case = TRUE))), names(data)),
sample_columns = match(names(select(data,-c(contains("blank", ignore.case = TRUE),"feature_number"))),
names(data)))
{
require("tidyverse")
data$max_blanks <- apply(data[blank_columns], 1, max)
data$mean_samples <- apply(data[sample_columns], 1, mean, na.rm = TRUE)
no_background <- data%>%
mutate(background_features = case_when(mean_samples*min_val > max_blanks ~ "real",
TRUE ~ "background"))%>%
dplyr::select(-c(max_blanks, mean_samples))
}
rename_sample_codes_ms <- function(x) {
new <- x%>%
mutate(sample_code_ms = gsub(".mzML", "", sample_code_ms),
sample_code_ms = gsub(".mzXML", "", sample_code_ms))%>%
left_join(sample_rename%>%
select(1:2), by = "sample_code_ms")%>%
select(-sample_code_ms)
}
map <- purrr::map
select <- dplyr::select
tidy <- broom::tidy
rename <- dplyr::rename
# LOADING -- Dataframes ---------------------------------------------------
sample_rename <- read_csv("./Raw/Rename_MS_SampleIDs.csv")%>%
rename(sample_code_ms = ID_MS,
sample_code = ID_new)
quant_raw <- read_csv("./Raw/quant_all.csv")%>%
select(-c(2:3))%>%
rename(feature_number = 1)%>%
gather(sample_code_ms, xic, 2:ncol(.))%>%
rename_sample_codes_ms()%>%
spread(sample_code, xic)
metadata_quant <- read_tsv("./Raw/Pn_metadata_table.tsv")%>%
mutate(filename = gsub("mzXML", "mzML", filename))%>%
rename(sample_code_ms = filename)%>%
rename_sample_codes_ms()
lib_id <- read_tsv("Raw/GNPS_LibIds.tsv")%>%
rename(feature_number = '#Scan#')%>%
mutate(feature_number = as.character(feature_number))
cat_df <- read_csv("./Raw/Pn_Ex2_MASTERx_Canopus_categories_probability.csv")
chl <- read_xlsx("Raw/Pn_Ex2_Chlorophyll.xlsx")
feature_info <- read_csv("./Raw/Pn_Ex2_MASTERx_elements.csv")%>%
rename(feature_number = 1)%>%
select(feature_number, everything())
sample_rename_16S <- read_csv("./Raw/Rename_16S_SampleIDs.csv")%>%
rename(sample_code_16S_old = ID_16S,
sample_code_16S = ID_16S_new)
otu_taxonomy <- read_tsv("./Raw/Pn_16S_no-plastids_taxonomy.tsv")%>%
rename("#OTU ID" = "Feature ID")
otu_df <- read_csv("./Raw/no-plastids-dada2-table.csv")%>%
gather(sample_code_16S_old, reads, 2:ncol(.))%>%
right_join(sample_rename_16S, by = "sample_code_16S_old")%>%
select(-sample_code_16S_old)%>%
spread(sample_code_16S, reads)%>%
left_join(otu_taxonomy,by = "#OTU ID")%>%
mutate(Taxon = gsub('D_[0-9]__', '', Taxon))%>%
select(-c("#OTU ID", "Confidence"))%>%
select("Taxon",everything())
# CLEANING -- Removing Blanks ---------------------------------------------
field_blanks <- (metadata_quant%>%
filter(SampleType == "blank_extraction"))$sample_code%>%
as.vector()
culture_blanks <- (metadata_quant%>%
filter(SampleType == "blank_culturemedia",
sample_code != "Media_Blank_100mL"))$sample_code%>%
as.vector()
culture_samples <- (metadata_quant%>%
filter(ATTRIBUTE_Experiment == "Exp2_Culture"))$sample_code%>%
as.vector()
quant_blanks_env <- quant_raw%>%
flag_background(blank_columns =  match(names(select(., field_blanks)), names(.)))%>%
filter(background_features == "real")%>%
select(-background_features)
quant_culture_blanks_removed <- quant_blanks_env%>%
select(c(feature_number, culture_blanks, culture_samples))%>%
flag_background(blank_columns = match(names(select(., culture_blanks)), names(.)))%>%
filter(background_features == "real")%>%
select(-background_features)
quant_df <- quant_blanks_env%>%
select(-c(culture_blanks, culture_samples))%>%
right_join(quant_culture_blanks_removed, by = "feature_number")
